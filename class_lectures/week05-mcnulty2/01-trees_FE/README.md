### Schedule

**9:00 am**: [Pair Problem](pair.md)

		Arianna, Vitoria
		Goodwin, Elizabeth
		John, Krisztian
		Emma, Adam
		Iggy, Laila
		Michael, Andree
		Saif, Brendon
		Rob, Dan
		Amine
		Maddy, Matt
		Angad, Druce

**10:30 am**: [Decision Trees and Random Forests](Decision_Trees_Random_Forests.pdf)

**11:20am**: Quiz

**12:00pm**: Food

**1:00 pm**: Investigation Presentation

**1:15 pm**: [Classification workflow & feature engineering with instacart data](fe_classimb_instacart/feature_engineering_instacart.ipynb)

**2:30 pm**: Work on Project

**Additional Tree Resources**:

* [Code for performing decision tree splits using gini, entropy, etc.](Classification_Tree_Splitting.ipynb)
* [RF code example on Ames housing data](Dec_Tree_Random_Forest_Ames.ipynb)
* [Another RF code example](RandomForest.ipynb)

### Reading

 * [Rutgers decision tree lecture](http://www.cs.rutgers.edu/~mlittman/courses/ml04/ch3.pdf) (some of our slides are based on this)
 * [Wisconsin decision tree lecture](http://pages.cs.wisc.edu/~jerryzhu/cs540/handouts/dt.pdf) (similar, more examples)
 * [Decision trees in sklearn](http://scikit-learn.org/stable/modules/tree.html) (including demo showing how to examine generated rules)
 * [Wikipedia entry on random forests](http://en.wikipedia.org/wiki/Random_forest)
 * [Wikipdia entry including information entropy](http://en.wikipedia.org/wiki/Entropy_%28information_theory%29)
 * [Using Python to build a decision tree from scratch](http://nbviewer.ipython.org/github/gumption/Python_for_Data_Science/blob/master/4_Python_Simple_Decision_Tree.ipynb)
 * A [notebook](http://nbviewer.ipython.org/gist/rcarneva/261dd7baa4a4a2a8bf2b) demonstrating gradient boosted trees, among other things.


