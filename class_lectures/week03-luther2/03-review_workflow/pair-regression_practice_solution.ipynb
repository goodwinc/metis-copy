{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pair Problem - Week2 - Day5 - Regression Practice\n",
    "\n",
    "Practice Lasso regularization technique in five steps:\n",
    "\n",
    "1) Load Diabetes Dataset from SK Learn (`sklearn.datasets.load_diabetes()`).  Note that data may already be normalized.\n",
    "\n",
    "2) Use the KFold function from sklearn's cross validation module to divide the data into 5 training/test sets.  Randomize the KFold (via the shuffle parameter with Random State of 0).\n",
    "\n",
    "3) Tune the lambda (alpha) parameter in the lasso model by looping over a grid of possible lambdas (sklearn: lasso)\n",
    "\n",
    "```\n",
    "For each candidate lambda, loop over the 5 training/test sets.  \n",
    "On each training/test set run the lasso model on the training set and then compute and record the prediction error in the test set.  \n",
    "Finally total the prediction error for the 5 training/test sets.\n",
    "```\n",
    "\n",
    "4) Set lambda to be the value that minimizes prediction error.\n",
    "\n",
    "5) Run the lasso model again with the optimal lambda determined in step 3. Which variables would you consider excluding on the basis of these results?\n",
    "\n",
    "6) Try with Ridge and ElasticNet and base LinearRegression Models.  Compare your results.\n",
    "\n",
    "Report the best score.\n",
    "\n",
    "**Extra Credit**:  Try some Feature Engineering (Polynomials etc) to fit the data better.  Plot the data to see relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function  # Python 2 and 3 Compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet, LinearRegression\n",
    "\n",
    "from sklearn.model_selection import (cross_val_score, train_test_split, \n",
    "                                     KFold, GridSearchCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* data Matrix is X and target vector is y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Hold Out Set to test different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_holdout, y_train, y_holdout = train_test_split(diabetes.data, diabetes.target, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Training Data into Multiple Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Notice that we are splitting the X_train data into 5 Folds\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_est = LinearRegression()\n",
    "\n",
    "scores = cross_val_score(lin_reg_est, X_train, y_train, cv=kfold)\n",
    "print(scores)\n",
    "print(\"Linear Reg Mean Score: \", np.mean(scores))\n",
    "\n",
    "# Build the Model\n",
    "lin_reg_est.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitted vs. Actual\n",
    "y_train_pred = lin_reg_est.predict(X_train)\n",
    "\n",
    "plt.scatter(y_train, y_train_pred, alpha=0.2)\n",
    "plt.plot([0, 400], [0, 400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitted vs. Actual\n",
    "y_test_pred = lin_reg_est.predict(X_holdout)\n",
    "\n",
    "plt.scatter(y_holdout, y_test_pred)\n",
    "plt.plot([0, 400], [0, 400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Residuals\n",
    "\n",
    "lin_reg_residuals = y_train - y_train_pred\n",
    "\n",
    "plt.scatter(y_train, lin_reg_residuals)\n",
    "plt.plot([0,400], [0, 0])\n",
    "plt.title(\"Actual vs. Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lasso Model:\")\n",
    "params = {\n",
    "    \"alpha\": np.logspace(-4, -.1, 20)\n",
    "}\n",
    "\n",
    "grid_est = GridSearchCV(Lasso(), param_grid=params, cv=kfold)\n",
    "grid_est.fit(X_train, y_train)\n",
    "df = pd.DataFrame(grid_est.grid_scores_)\n",
    "df[\"alpha\"] = df.parameters.apply(lambda val: val[\"alpha\"])\n",
    "plt.plot(np.log(df.alpha), df.mean_validation_score);\n",
    "grid_est.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_est.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['alpha']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ridge Model:\")\n",
    "params = {\n",
    "    \"alpha\": np.logspace(-4, -.1, 20)\n",
    "}\n",
    "\n",
    "grid_est = GridSearchCV(Ridge(), param_grid=params, cv=kfold)\n",
    "grid_est.fit(X_train, y_train)\n",
    "df = pd.DataFrame(grid_est.grid_scores_)\n",
    "df[\"alpha\"] = df.parameters.apply(lambda val: val[\"alpha\"])\n",
    "plt.plot(np.log(df.alpha), df.mean_validation_score);\n",
    "grid_est.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Functions for repeatable Code - DRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_grid_search_est(model, X, y, cv=5, **params):\n",
    "    \n",
    "    grid_est = GridSearchCV(model, param_grid=params, cv=cv)\n",
    "    grid_est.fit(X, y)\n",
    "    df = pd.DataFrame(grid_est.grid_scores_)\n",
    "    for param in params:\n",
    "        df[param] = df.parameters.apply(lambda val: val[param])\n",
    "#         plt.plot(np.log(df.alpha), df.mean_validation_score);\n",
    "        plt.semilogx(df.alpha, df.mean_validation_score)\n",
    "    grid_est.grid_scores_\n",
    "    return grid_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lasso Grid Search\")\n",
    "lasso_grid_est = build_grid_search_est(Lasso(), X_train, y_train, cv=kfold,\n",
    "                                       alpha=np.logspace(-4, -1, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ridge Grid Search\")\n",
    "ridge_grid_est = build_grid_search_est(Ridge(), X_train, y_train, cv=kfold,\n",
    "                                       alpha=np.logspace(-4, -1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Elastic Net Grid Search\")\n",
    "elastic_net_grid_est = build_grid_search_est(ElasticNet(), X_train, y_train, cv=kfold,\n",
    "                                             alpha=np.logspace(-4, 0.1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lasso Grid Scores\")\n",
    "lasso_grid_est.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ridge Grid Scores\")\n",
    "ridge_grid_est.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Elatic Net Grid Scores\")\n",
    "elastic_net_grid_est.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Models using Holdout Set across these four models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "y_pred = lin_reg_est.predict(X_holdout)\n",
    "print(\"Linear Regression:\", r2_score(y_holdout, y_pred))\n",
    "\n",
    "y_pred = lasso_grid_est.predict(X_holdout)\n",
    "print(\"Lasso Regression:\", r2_score(y_holdout, y_pred))\n",
    "\n",
    "y_pred = ridge_grid_est.predict(X_holdout)\n",
    "print(\"Ridge Regression:\", r2_score(y_holdout, y_pred))\n",
    "\n",
    "y_pred = elastic_net_grid_est.predict(X_holdout)\n",
    "print(\"ElasticNet Regression:\", r2_score(y_holdout, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(zip(range(10), lasso_grid_est.best_estimator_.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diabetes_df = pd.DataFrame(diabetes.data)\n",
    "diabetes_df.columns = [\"X\" + str(col) for col in diabetes_df.columns]\n",
    "diabetes_df[\"target\"] = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(diabetes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "lm_poly = LinearRegression()\n",
    "lm_poly.fit(poly.fit_transform(X_train), y_train)\n",
    "y_pred = lm_poly.predict(poly.transform(X_holdout))\n",
    "print(\"Polynomial Regression:\", r2_score(y_holdout, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting fancy - we can do at least a little bit better\n",
    "#(I should have cross-validated these to be rigorous)\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=2000, max_features=3, max_depth=5)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_holdout)\n",
    "print(\"Random Forest Regression:\", r2_score(y_holdout, y_pred))\n",
    "\n",
    "gbm = GradientBoostingRegressor(n_estimators=500, max_depth=3, learning_rate=.01)\n",
    "gbm.fit(X_train, y_train)\n",
    "y_pred = gbm.predict(X_holdout)\n",
    "print(\"Gradient Boosted Regression:\", r2_score(y_holdout, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's more like it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(y_pred, y_holdout, kind='regplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
