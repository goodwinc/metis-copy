{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16b_Scrape_Book_Details_Random_Samples\n",
    "\n",
    "Author: Daniel Hui\n",
    "\n",
    "License: MIT\n",
    "\n",
    "This notebook takes the URLs from te previous notebook and extracts book-specific features, such as ratings, reviews, and book size dimensions and page number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_range = 250.  #set max records per file to be saved incrementally\n",
    "location = 'random'  #set library branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Field-Level Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "#Definition for finding information that is next to a text field\n",
    "def find_text(textsoup, field):\n",
    "    info = textsoup.find(text=re.compile(field))\n",
    "    if info:\n",
    "        return info.findNext().text.strip()\n",
    "    else: \n",
    "        return 'N/A'\n",
    "\n",
    "#function to extract book description\n",
    "def find_description(textsoup):\n",
    "    try:\n",
    "        dictionary_string = textsoup.find(\"script\",text=re.compile(\"@graph\")).text  #this is a dictionary string \n",
    "        book_dict = ast.literal_eval(dictionary_string)                             #turn it into an actual dict\n",
    "        book_details = []                                                           #empty list to hold book details\n",
    "        book_sub_dict = book_dict.get(\"@graph\")[0]\n",
    "        ratings_dict = book_sub_dict.get(\"aggregateRating\")\n",
    "        try:                                                                #Avg Rating\n",
    "            book_details.append(ratings_dict.get(\"ratingValue\"))\n",
    "        except: book_details.append(\"N/A\")\n",
    "        try:                                                                #num of Ratings\n",
    "            book_details.append(ratings_dict.get(\"ratingCount\"))\n",
    "        except: book_details.append(0)\n",
    "        try:                                                                #num of Reviews\n",
    "            book_details.append(ratings_dict.get(\"reviewCount\"))\n",
    "        except: book_details.append(0)  \n",
    "        try:                                                                #Hardcover/Softcover\n",
    "            book_details.append(book_sub_dict.get(\"bookFormat\").get(\"@id\"))\n",
    "        except: book_details.append(\"N/A\")  \n",
    "        try:                                                                #Subject areas\n",
    "            book_details.append(book_sub_dict.get(\"about\"))                                 \n",
    "        except: book_details.append(\"N/A\")   \n",
    "        try:                                                                #URL to book image\n",
    "            book_details.append(book_sub_dict.get(\"image\"))                        \n",
    "        except: book_details.append(\"N/A\")  \n",
    "        try:                                                                #Book description\n",
    "            if len(book_sub_dict.get(\"description\")[0]) > 1:\n",
    "                book_details.append(book_sub_dict.get(\"description\")[0])\n",
    "            else: book_details.append(book_sub_dict.get(\"description\"))     #some cases this is needed\n",
    "        except: book_details.append(\"N/A\")              \n",
    "        return book_details    \n",
    "    except:\n",
    "        return 7*['N/A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book-Level Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_data(url_row):\n",
    "    \n",
    "    response = requests.get(f\"{url_row}?active_tab=bib_info\")        #take in the URL\n",
    "    webpage = response.text\n",
    "    soup = BeautifulSoup(webpage, \"lxml\")\n",
    "    \n",
    "    this_book_data = [url_row] \n",
    "    this_book_data.append(find_text(soup,'Characteristic'))          #Number of Pages, Book Size\n",
    "    this_book_data.append(find_text(soup,'Branch Call Number'))      #Library Call Number \n",
    "    this_book_data = this_book_data + find_description(soup)         #concat two lists\n",
    "    \n",
    "    return this_book_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the page count\n",
    "def get_page_count(row):\n",
    "    try:\n",
    "        row = row.replace(\" unnumbered\",\"\")    #handle cases where there are unnumbered pages\n",
    "        if 'pages' in row:\n",
    "            if len(row.split(' page')[0].strip().split(\" \")) == 2:\n",
    "                return row.split(' page')[0].strip().split(\" \")[-1]\n",
    "            else: return row.split(' page')[0].strip()\n",
    "        else: return 'N/A'\n",
    "    except: return 'N/A'\n",
    "\n",
    "#extract the book dimensions\n",
    "def get_book_dims(row):\n",
    "    try:\n",
    "        if 'cm' in row:\n",
    "            if len(row.split(' cm')[0].strip().split(\" \")) == 1:\n",
    "                return row.split(' cm')[0].strip()\n",
    "            else: return row.split(' cm')[0].strip().split(\" \")[-1]\n",
    "        else: return 'N/A'\n",
    "    except: return 'N/A'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load URLS, Divide into DataFrame Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df = pd.DataFrame(pd.read_csv(F\"../01_Data/04_Scraped/isbn_url_{location}.csv\",index_col=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df = url_df[url_df['link'].notna()]   #remove lines with no URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the URL List into chunks so you can incrementally save\n",
    "total_loops = (len(url_df) // max_range) + 1\n",
    "url_dframes = np.array_split(url_df, total_loops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(url_dframes)):                             #adjust the lower number if the scrape stalled\n",
    "    dframe = url_dframes[i]\n",
    "    dframe = dframe.reset_index()                                #reset index so the ISBN below can match\n",
    "    dframe[\"data\"] = dframe[\"link\"].apply(get_book_data)\n",
    "    \n",
    "    book_df = pd.DataFrame(list(dframe[\"data\"]))                                      #turn data into dataframe\n",
    "    book_df = book_df.rename({0: 'url', 1: 'page_dim', 2: 'callno', 3:'avg_rating',   #rename columns\n",
    "                     4:'tot_ratings', 5: 'tot_reviews', 6:'type', 7:'subjects',\n",
    "                     8: 'image', 9: 'desc'}, axis=1)\n",
    "\n",
    "    #Clean Data.                                                  #Remove repetitive part of image URL\n",
    "    book_df[\"page\"] = book_df[\"page_dim\"].apply(get_page_count)   #Extract Page Number\n",
    "    book_df[\"dim\"] = book_df[\"page_dim\"].apply(get_book_dims)     #Extract book dimensions\n",
    "    book_df[\"isbn\"] = dframe[\"isbn\"]\n",
    "    \n",
    "    #Keep useful columns\n",
    "    book_df = book_df[[\"isbn\",\"url\",\"page\",\"dim\",\"avg_rating\",\"tot_ratings\",\"tot_reviews\",\n",
    "                       \"type\",\"callno\",\"subjects\",\"desc\",\"image\"]]\n",
    "    \n",
    "    book_df.to_csv(f'../01_Data/04_Scraped/book_data_{location}_{i}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Files Together into Combined Branch CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start a dataframe with the first CSV\n",
    "book_data_df = pd.read_csv(f'../01_Data/04_Scraped/book_data_{location}_0.csv',index_col=0)\n",
    "\n",
    "#loop remaining CSVs\n",
    "for i in range(1,len(url_dframes)):                                                          \n",
    "    temp_df = pd.read_csv(f'../01_Data/04_Scraped/book_data_{location}_{i}.csv',index_col=0)\n",
    "    book_data_df = pd.concat([book_data_df,temp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_data_df.to_csv(f'../01_Data/04_Scraped/book_data_{location}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
