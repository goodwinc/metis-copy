{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions to apply to the dataframe\n",
    "def clean_url(row):                             #Extract URL from Link\n",
    "    return row['link'].find(\"a\")['href']\n",
    "\n",
    "def clean_text(row):                            #Extract Text\n",
    "    return row.text\n",
    "\n",
    "def get_date(row):                              #Extract Date from Link\n",
    "    if row.text == '-':\n",
    "        return ''\n",
    "    else: return row.find(\"a\")['href'][47:57]   \n",
    "\n",
    "def clean_num(row):                             #Extract Number and strip non numerical parts\n",
    "    return row.text.replace('$','').replace(',','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "#Scrape Data from Website                                             \n",
    "#years = [3,range(2008,2018)]                           #The first number is the # of pages(-1) for each year to scrape\n",
    "years = [3,range(1988,1998)]                           #the second is the range of years you want to scrape\n",
    "\n",
    "for year in years[1]:\n",
    "    movie_data = [] \n",
    "    for page in range(1,years[0]):                     #the top number in the range sets how many sequential pages you want to scrape\n",
    "        response = requests.get('https://www.boxofficemojo.com/yearly/chart/?page={}&view=releasedate&view2=domestic&yr={}&p=.htm'.format(page,year))\n",
    "        print(response.status_code)\n",
    "\n",
    "        webpage = response.text\n",
    "        soup = BeautifulSoup(webpage, \"lxml\")\n",
    "        tables_soup = soup.find_all('table')[6]         #this is the soup that contains just the table I want\n",
    "        rows_soup = tables_soup.find_all('tr')          #This is a soup that contains all of the rows in the table \n",
    "\n",
    "        for j in range(2,102):                          #this sets the range for rows, which the first movie is at \n",
    "                                                        #index 2 and the last is at index 101\n",
    "            data_soup = rows_soup[j].find_all('td')     #turn each row into a soup object of data\n",
    "            row_data = []                               #start an empty list\n",
    "            for i in range(0,8):\n",
    "                row_data.append(data_soup[i])           #add each data item to the list\n",
    "            movie_data.append(row_data)                 #at the end of a row, add that row list to the full movie list\n",
    "            \n",
    "    #turn big movie list into DataFrame\n",
    "    movie_df = pd.DataFrame(movie_data)             \n",
    "\n",
    "    #Rename columns in the dataframe to the names in the table/chart\n",
    "    movie_df = movie_df.rename({0:'rank', 1: \"link\", 2: \"studio\", 3: \"total_box\", \n",
    "                                    4:'max_sites', 5: \"open_box\", 6:'open_sites', \n",
    "                                    7:'open_date', 8: 'close_date' }, axis='columns')#\n",
    "    \n",
    "    #Apply definitions to clean data\n",
    "    movie_df['url'] = movie_df.apply(clean_url,axis=1)                #Clean URL\n",
    "    movie_df['title'] = movie_df['link'].apply(clean_text)            #Clean Title\n",
    "    movie_df['rank'] = movie_df['rank'].apply(clean_text)             #Clean rank\n",
    "    movie_df['studio'] = movie_df['studio'].apply(clean_text)         #Clean Studio Name\n",
    "    movie_df['total_box'] = movie_df['total_box'].apply(clean_num)    #Clean Total Box Office\n",
    "    movie_df['max_sites'] = movie_df['max_sites'].apply(clean_num)    #Clean Max Number of Theaters\n",
    "    movie_df['open_box'] = movie_df['open_box'].apply(clean_num)      #Clean Opening Weekend Box Office\n",
    "    movie_df['open_sites'] = movie_df['open_sites'].apply(clean_num)  #Clean Opening Weekend NUmber of Theaters\n",
    "    movie_df['open_date'] = movie_df['open_date'].apply(get_date)     #Clean Opening Date\n",
    "    #movie_df['close_date'] = movie_df['close_date'].apply(clean_text)#Clean Closing Date\n",
    "\n",
    "    movie_df.drop(['link'], axis=1,inplace = True)\n",
    "    \n",
    "    #Save CSV with filename 'year_movies.csv'\n",
    "    movie_df.to_csv('../04_Data/{}_movies.csv'.format(year))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
