{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Krisztian Sandor - KAGGLE Music Recommendation classification model - 25.10.2018.\n",
    "## Music recommendation engine for KKBOX users based on KAGGLE competition\n",
    "source: https://www.kaggle.com/c/kkbox-music-recommendation-challenge\n",
    "\n",
    "---\n",
    "\n",
    "**1. Objective:** Predict the chances of a user listening to a song repetitively after the first observable listening event within a time window was triggered\n",
    "\n",
    "**2. Baseline model:**\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "X_train_small = X_train[['user_activity','artist_freq','number_of_genres_listened','n_th_time_this_genre']]\n",
    "X_val_small = X_val[['user_activity','artist_freq','number_of_genres_listened','n_th_time_this_genre']]\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_small, y_train)\n",
    "fbeta_score(lr.predict(X_val_small), y_val,beta=0.3)\n",
    "```\n",
    "\n",
    "The simple model above results in FBeta score of ~0.83. The target variable is 1 if the user repetitively listens to a song within a month timeframe, and 0 if not. The independent variables are \n",
    "- user_activity: # of songs the user has listened to\n",
    "- artist_freq: # of times the user has listened to the specific artist\n",
    "- number_of_genres_listened: # of distinct genres the user listens to\n",
    "- n_th_time_this_genre: # of times the user has listened to the same genre as the song in question\n",
    "\n",
    "The score indicates that the baseline classification model offers a relatively strong benchmark, however there is clear room for improvement. My aim is to only offer songs to the users they would like, even at an expense of offering less songs. For this reason I am using FBeta with beta=1/3 to offer more weight on precision, rather than recall. This is also supported by the fact that my target metrics are almost 50%-50% distributed in the dataset.\n",
    "\n",
    "Below I describe the brief methodology of my next steps.\n",
    "\n",
    "**3. Next steps:**\n",
    "1. Test and hopefully use decision tree models, given high number of NaNs\n",
    "2. Use additional data: genre, screen where user clicked play, billboard chart ranking of song, etc.\n",
    "3. Apply strong regularization to data, given huge sparse matrices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
